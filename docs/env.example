# Copy this file to .env at the repo root and edit for your setup.
#
# The benchmark uses an OpenAI-compatible HTTP API (llama.cpp, LM Studio, etc.).
# Set the base URL to wherever your llama-server is listening.

OPENAI_BASE_URL=http://localhost:8080/v1
OPENAI_API_KEY=not-needed

# Directory where Inspect AI writes eval logs (gitignored by default)
INSPECT_LOG_DIR=./logs
